{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classify text using fast.ai\n",
    "\n",
    "This notebook will walk you through a simple example that trains a model to determine if there's a bicycle in an image and then use that to find bicycles in a video.\n",
    "\n",
    "This work is based on the early lessons in [Practical Deep Learning for Coders](https://course.fast.ai/), taught online by Jeremy Howard. I **highly** recommend this free online course.\n",
    "\n",
    "## Using this notebook\n",
    "\n",
    "Essentially you need a computer that's running a GPU running fast.ai. There are a few ways to do this without owning a computer with a GPU (I certainly don't). There are [lots of options](https://course.fast.ai/index.html). I like to use use [the Amazon EC2 setup](https://course.fast.ai/start_aws.html), which is probably the most complicated. In most of these cases, you'll just clone [the workshop repository](https://github.com/Quartz/aistudio-workshops) and get the notebook running.\n",
    "\n",
    "I'm also tailoring this notebook for use with [Google Colaboratory](https://colab.research.google.com), which as of this writing is the fastest, cheapest (free) way to get going.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### If you're using Google Colaboratory ...\n",
    "\n",
    "Be aware that Google Colab instances are ephemeral -- they vanish *Poof* when you close them, or after a period of sitting idle (currently 90 minutes).\n",
    "\n",
    "There are great steps on the fast.ai site for [getting started with fast.ai an Google Colab](https://course.fast.ai/start_colab.html). \n",
    "\n",
    "Those instructions will show you how to save your own copy of this _notebook_ to Google Drive.\n",
    "\n",
    "They also tell you how to save a copy of your _data_ to Google Drive (Step 4), which is unneccesary for this workshop. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## ALL GOOGLE COLAB USERS RUN THIS CELL\n",
    "\n",
    "## This runs a script that installs fast.ai\n",
    "!curl -s https://course.fast.ai/setup/colab | bash"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### If you are _not_ using Google Colaboratory ...\n",
    "\n",
    "Run the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## NON-COLABORATORY USERS SHOULD RUN THIS CELL\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Everybody do this ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## AND *EVERYBODY* SHOULD RUN THIS CELL\n",
    "\n",
    "from fastai.text import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Plan\n",
    "\n",
    "Given a set of political Facebook ads, we want to sort them into three categories: fundraising, list-building, and persuasion.\n",
    "\n",
    "We're going to take a hand-coded set of 1,700 ads (which Jeremy B. Merrill coded on a long flight), and apply them to the larger Facebook ad database. As of this writing, that database has nearly 165,000 ads and clocks in about 3.2 GB. So for this class, as a proof of concept, we'll take a slice 5,000 ads.\n",
    "\n",
    "Our plan will be:\n",
    "\n",
    "- Download an English-language recognition **language model** pre-trained on Wikipedia articles\n",
    "- Further train that **language model** on the type of English we're working with, specifically the corpus of Facebook ads we have\n",
    "- Train a **classification model** on the difference between fundraising, list-building, and persuasion ads.\n",
    "- Use that **classification model** model to label the bigger group of ads"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's get the two data sets we'll be using: The hand-labeled set of 1,700 ads and the raw set of 5,000 ads."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget -N https://qz-aistudio-public.s3.amazonaws.com/workshops/facebook_ad_data.zip\n",
    "!unzip facebook_ad_data.zip > /dev/null\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you have a subdirectory called `facebook_ad_data` which contains two files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%ls facebook_ad_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we'll load the `hand-labeled-ads.csv` file into a structure called a \"data frame,\" which is a common way to handle large amounts of data in python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hand_coded_ads = pd.read_csv('facebook_ad_data/hand-labeled-ads.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a peek!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hand_coded_ads.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And let's load in the 5,000 raw ads."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_ads = pd.read_csv('facebook_ad_data/fbpac-ads-en-US-slice.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_ads.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A little cleaning\n",
    "\n",
    "We want to study the \"message\" line in each row, but it's got a bunch of html tags inside..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_ads.iloc[0]['message']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code will clean it all up for us!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def remove_html_tags(text):\n",
    "    \"\"\"Remove html tags from a string\"\"\"\n",
    "    clean = re.compile('<.*?>')\n",
    "    return re.sub(clean, '', text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try it ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_html_tags(raw_ads.iloc[0]['message'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahhh, that's better. OK, let's make a new column called \"clean_message\" in our data sets applying this function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hand_coded_ads['clean_message'] = hand_coded_ads['message'].apply(remove_html_tags)\n",
    "raw_ads['clean_message'] = raw_ads['message'].apply(remove_html_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hand_coded_ads.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hand_coded_ads.iloc[4]['message']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hand_coded_ads.iloc[4]['clean_message']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Language Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we're going to take a model trained on Wikipedia and give it some additional training on Facebook ads. We can use all of the data we have available to make this work better, so we're going to make a dataframe of ALL of our ads."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_ads = pd.concat([hand_coded_ads,raw_ads], sort=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(all_ads), len(hand_coded_ads), len(raw_ads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This takes the first 80% of the rows as the training row, and the rest as validation\n",
    "# all_ads_train = all_ads.sample(frac=0.8,random_state=200)\n",
    "# all_ads_validation = all_ads.drop(all_ads_train.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading in data with the TextLMDataBunch factory class, using all the defaults\n",
    "# data_lm = TextLMDataBunch.from_df('facebook_ad_data', train_df=all_ads_train, valid_df=all_ads_validation, text_cols='clean_message')\n",
    "\n",
    "data_lm = (TextList.from_df(all_ads, cols=['clean_message'])\n",
    "    .split_by_rand_pct(0.2)\n",
    "    .label_for_lm()\n",
    "    .databunch(bs=64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_lm.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_lm.show_batch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll actually train the language model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn_lm = language_model_learner(data_lm, AWD_LSTM, drop_mult=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn_lm.lr_find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn_lm.recorder.plot(suggestion=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn_lm.fit_one_cycle(1, 7e-02, moms=(0.8,0.7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn_lm.fit_one_cycle(2, 1e-01, moms=(0.8,0.7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optionally save and reload the model (file is about 150MB)\n",
    "learn_lm.save('fit_head')\n",
    "learn_lm.load('fit_head');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This takes a few minutes!\n",
    "learn_lm.unfreeze()\n",
    "learn_lm.fit_one_cycle(4, 1e-3, moms=(0.8,0.7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXT = \"I wonder if this\"\n",
    "N_WORDS = 40\n",
    "N_SENTENCES = 3\n",
    "\n",
    "print(\"\\n\".join(learn_lm.predict(TEXT, N_WORDS, temperature=0.75) for _ in range(N_SENTENCES)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the encoder we used for this ...\n",
    "learn_lm.save_encoder('fine_tuned_encoder2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Classification Model\n",
    "\n",
    "This is where we use the language model to train a new model that will learn to classify ads as fundraising, listbuilding, and persuasion. \n",
    "\n",
    "First, we train it on the hand-coded ads, splitting them into \"training\" and \"validation\" sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_lm = load_data('facebook_ad_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# data_clas = TextClasDataBunch.from_df('facebook_ad_data', train_df=hand_coded_train, valid_df=hand_coded_validation, vocab=data_lm.vocab, text_cols='clean_message', label_cols='label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_clas = (TextList.from_df(hand_coded_ads, cols=['clean_message','label'], vocab=data_lm.vocab)\n",
    "    .split_by_rand_pct(0.2)\n",
    "    .label_from_df(cols='label')\n",
    "    .databunch(bs=64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_clas.show_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_learner2 = text_classifier_learner(data_clas, AWD_LSTM, drop_mult=0.5)\n",
    "class_learner2.load_encoder('fine_tuned_encoder2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class_learner2.lr_find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_learner2.recorder.plot(suggestion=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 1e-02\n",
    "class_learner2.freeze()\n",
    "class_learner2.fit_one_cycle(1,slice(lr/(2.6**4),lr), moms=(0.8,0.7) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_learner2.fit_one_cycle(2,slice(lr/(2.6**4),lr), moms=(0.8,0.7) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "class_learner.freeze_to(-2)\n",
    "class_learner.fit_one_cycle(1,slice(lr/(2.6**4),lr), moms=(0.8,0.7) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "class_learner.freeze_to(-2)\n",
    "class_learner.fit_one_cycle(1,slice(lr/(2.6**4),lr), moms=(0.8,0.7) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_learner.fit_one_cycle(3,slice(lr/(2.6**4),lr), moms=(0.8,0.7) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_learner.freeze()\n",
    "class_learner.fit_one_cycle(1,slice(lr/(2.6**4),lr), moms=(0.8,0.7) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_learner.freeze_to(-3)\n",
    "class_learner.fit_one_cycle(3,slice(lr/(2.6**4),lr), moms=(0.8,0.7) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_learner.lr_find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_learner.recorder.plot(suggestion=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
